{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры:\n",
    "* https://github.com/bigartm/bigartm-book/blob/master/ARTM_example_RU.ipynb\n",
    "* https://github.com/bigartm/bigartm-book/blob/master/ARTM_tutorial_RU.ipynb\n",
    "* http://localhost:8888/notebooks/examples/2/%D0%94%D0%B5%D0%BC%D0%BE%D0%BD%D1%81%D1%82%D1%80%D0%B0%D1%86%D0%B8%D1%8F-BigARTM-0.8.0.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import artm\n",
    "\n",
    "# Адрес, по которому находятся данные\n",
    "BATCH_ADRESS = 'batches_news'\n",
    "\n",
    "# Вывод версии BigARTM\n",
    "print(artm.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка адреса, по которому находятся данные\n",
    "batch_vectorizer = artm.BatchVectorizer(\n",
    "    data_path=BATCH_ADRESS, data_format='batches'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  75725 - количество слов в словаре\n",
      "  19855 - количество слов в словаре после фильтрации по min_tf\n",
      "  19310 - количество слов в словаре после фильтрации по max_tf\n",
      "   1819 - количество слов в словаре после фильтрации по min_df_rate\n",
      "   1819 - количество слов в словаре после фильтрации по max_df_rate\n"
     ]
    }
   ],
   "source": [
    "# Пересоздание словаря для модели и сохранение его в файл\n",
    "\n",
    "# Устанавливается название словаря для модели\n",
    "dictionary_address = BATCH_ADRESS + '/dictionary.dict'\n",
    "\n",
    "# Инициализация словоря для модели\n",
    "dictionary = artm.Dictionary()\n",
    "\n",
    "# Удаление словаря, оставшегося после предыдущих запусков\n",
    "if os.path.isfile(dictionary_address):\n",
    "    os.remove(dictionary_address)\n",
    "    \n",
    "# Сохранение словаря в файл\n",
    "dictionary.gather(data_path=batch_vectorizer.data_path)\n",
    "dictionary.save(dictionary_path=dictionary_address)\n",
    "\n",
    "# Загрузка словаря из файла\n",
    "dictionary.load(dictionary_path=dictionary_address)\n",
    "print(\n",
    "    '{:>7}'.format(dictionary.__dict__['_master'].get_info().dictionary[0].num_entries),\n",
    "    \"- количество слов в словаре\"\n",
    ")\n",
    "\n",
    "\n",
    "# Фильтрация\n",
    "\n",
    "# Убираются редкие слова по всей коллекции\n",
    "# Слово встречается во всей коллекции больше чем n раз\n",
    "dictionary.filter(min_tf=10)\n",
    "print(\n",
    "    '{:>7}'.format(dictionary.__dict__['_master'].get_info().dictionary[0].num_entries),\n",
    "    \"- количество слов в словаре после фильтрации по min_tf\", \n",
    ")\n",
    "\n",
    "# Убираются частые слова по всей коллекции\n",
    "# Слово встречается во всей коллекции меньше чем n раз\n",
    "dictionary.filter(max_tf=2000)\n",
    "print(\n",
    "    '{:>7}'.format(dictionary.__dict__['_master'].get_info().dictionary[0].num_entries),\n",
    "    \"- количество слов в словаре после фильтрации по max_tf\", \n",
    ")\n",
    "\n",
    "# Убираются слова, которые попадаются меньше чем в n процентов документов\n",
    "dictionary.filter(min_df_rate=0.01)\n",
    "print(\n",
    "    '{:>7}'.format(dictionary.__dict__['_master'].get_info().dictionary[0].num_entries),\n",
    "    \"- количество слов в словаре после фильтрации по min_df_rate\", \n",
    ")\n",
    "\n",
    "# Убираются слова, которые попадаются больше чем в n процентов документов\n",
    "dictionary.filter(max_df_rate=0.6)\n",
    "print(\n",
    "    '{:>7}'.format(dictionary.__dict__['_master'].get_info().dictionary[0].num_entries),\n",
    "    \"- количество слов в словаре после фильтрации по max_df_rate\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_default_model(topic_count, dictionary):\n",
    "    \n",
    "    # Создание модели\n",
    "    model_artm = artm.ARTM(\n",
    "        # Названия тем\n",
    "        topic_names=['topic_{0:0>3}'.format(i) for i in range(topic_count)], \n",
    "        # Разрешается хранить матрицу theta в памяти\n",
    "        cache_theta=True,\n",
    "        # Фиксация seed для воспроизвдимости результатов\n",
    "        seed=-1,\n",
    "        # Настройка - сколько раз обрабатывать каждый документ\n",
    "        num_document_passes=1,\n",
    "        # Модальности\n",
    "        #class_ids={'text': 1.0},\n",
    "    )\n",
    "\n",
    "    # Инициализация модели\n",
    "    model_artm.initialize(dictionary=dictionary)\n",
    "\n",
    "    # Установка отслеживаемых параметров\n",
    "    # Перплексия (чем она меньше тем лучше)\n",
    "    model_artm.scores.add(artm.PerplexityScore(name='PerplexityScore'))\n",
    "    # Разреженность матрицы Phi (доля почти нулевых значений)\n",
    "    model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "    # Разреженность матрицы Theta (доля почти нулевых значений)\n",
    "    model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "    # Анализ самых используемых слов по темам\n",
    "    model_artm.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=10))\n",
    "    # Анализ ядра тем на контраст и чистоту\n",
    "    model_artm.scores.add(artm.TopicKernelScore(name='TopicKernelScore'))\n",
    "    #model_artm.scores.add(artm.TopicKernelScore(name='TopicKernelScore', probability_mass_threshold=0.3))\n",
    "    \n",
    "    return model_artm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_print_results(model_artm):\n",
    "    \n",
    "    # Графики\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 20))\n",
    "\n",
    "    ax = plt.subplot2grid((4,3), (0,0), colspan = 1, rowspan = 1,  fig=fig)\n",
    "    ax.plot(model_artm.score_tracker[\"PerplexityScore\"].value, color='tab:blue')\n",
    "    ax.set_xlabel('Iterations count')\n",
    "    ax.set_ylabel('PerplexityScore')\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = plt.subplot2grid((4,3), (0,1), colspan = 1, rowspan = 1,  fig=fig)\n",
    "    ax.plot(model_artm.score_tracker[\"SparsityPhiScore\"].value, color='tab:blue')\n",
    "    ax.set_xlabel('Iterations count')\n",
    "    ax.set_ylabel('SparsityPhiScore')\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim([0,1])\n",
    "\n",
    "    ax = plt.subplot2grid((4,3), (0,2), colspan = 1, rowspan = 1,  fig=fig)\n",
    "    ax.plot(model_artm.score_tracker[\"SparsityThetaScore\"].value, color='tab:blue')\n",
    "    ax.set_xlabel('Iterations count')\n",
    "    ax.set_ylabel('SparsityThetaScore')\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim([0,1])\n",
    "\n",
    "\n",
    "    ax = plt.subplot2grid((4,3), (1,0), colspan = 1, rowspan = 1,  fig=fig)\n",
    "    ax.plot(model_artm.score_tracker[\"TopicKernelScore\"].average_contrast, color='tab:blue')\n",
    "    ax.set_xlabel('Iterations count')\n",
    "    ax.set_ylabel('TopicKernelScore_average_contrast')\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim([0,1])\n",
    "\n",
    "    ax = plt.subplot2grid((4,3), (1,1), colspan = 2, rowspan = 1,  fig=fig)\n",
    "    my_contrast_dictionary = model_artm.score_tracker['TopicKernelScore'].last_contrast\n",
    "    ax.bar(my_contrast_dictionary.keys(), my_contrast_dictionary.values(), 0.5, color='tab:blue')\n",
    "    ax.set_xlabel('//')\n",
    "    ax.set_ylabel('//')\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "\n",
    "    ax = plt.subplot2grid((4,3), (2,0), colspan = 1, rowspan = 1,  fig=fig)\n",
    "    ax.plot(model_artm.score_tracker['TopicKernelScore'].average_purity, color='tab:blue')\n",
    "    ax.set_xlabel('Iterations count')\n",
    "    ax.set_ylabel('TopicKernelScore_average_purity')\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim([0,1])\n",
    "\n",
    "    ax = plt.subplot2grid((4,3), (2,1), colspan = 2, rowspan = 1,  fig=fig)\n",
    "    my_purity_dictionary = model_artm.score_tracker['TopicKernelScore'].last_purity\n",
    "    ax.bar(my_purity_dictionary.keys(), my_purity_dictionary.values(), 0.5, color='tab:blue')\n",
    "    ax.set_xlabel('//')\n",
    "    ax.set_ylabel('//')\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "\n",
    "    ax = plt.subplot2grid((4,3), (3,0), colspan = 1, rowspan = 1,  fig=fig)\n",
    "    my_average_size = model_artm.score_tracker['TopicKernelScore'].average_size\n",
    "    ax.plot(my_average_size, color='tab:blue')\n",
    "    ax.plot([model_artm.phi_.shape[0]/model_artm.num_topics for i in range(len(my_average_size))], color='tab:orange')\n",
    "    ax.set_xlabel('Iterations count')\n",
    "    ax.set_ylabel('TopicKernelScore_average_size')\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim([0,ax.get_ylim()[1]])\n",
    "\n",
    "    ax = plt.subplot2grid((4,3), (3,1), colspan = 2, rowspan = 1,  fig=fig)\n",
    "    my_size_dictionary = model_artm.score_tracker['TopicKernelScore'].last_size\n",
    "    ax.bar(my_size_dictionary.keys(), my_size_dictionary.values(), 0.5, color='tab:blue')\n",
    "    ax.plot([model_artm.phi_.shape[0]/model_artm.num_topics for i in range(model_artm.num_topics)], color='tab:orange')\n",
    "    ax.set_xlabel('//')\n",
    "    ax.set_ylabel('//')\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Конечные значения\n",
    "    \n",
    "    print(\"PerplexityScore:\", model_artm.score_tracker[\"PerplexityScore\"].last_value)\n",
    "    print(\"SparsityPhiScore:\", model_artm.score_tracker[\"SparsityPhiScore\"].last_value)\n",
    "    print(\"SparsityThetaScore:\", model_artm.score_tracker[\"SparsityThetaScore\"].last_value)\n",
    "    print()\n",
    "    print(\"TopicKernelScore_average_contrast:\", model_artm.score_tracker[\"TopicKernelScore\"].last_average_contrast)\n",
    "    print(\"TopicKernelScore_average_purity:\", model_artm.score_tracker['TopicKernelScore'].last_average_purity)\n",
    "    print(\"TopicKernelScore_average_size:\", model_artm.score_tracker['TopicKernelScore'].last_average_size)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "    # Главные слова в темах\n",
    "    \n",
    "    print(\"TopTokensScore:\")\n",
    "    topic_list = list(model_artm.score_tracker['TopTokensScore'].last_tokens.keys())\n",
    "    for topic_name in topic_list:\n",
    "        print(topic_name + ': ', end='')\n",
    "        for token_name in model_artm.score_tracker['TopTokensScore'].last_tokens[topic_name]:\n",
    "            print(token_name, end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'topic_count': 20,\n",
    "    'num_collection_passes': 40,\n",
    "    'SparsePhi': {\n",
    "        'name': 'SparsePhi',\n",
    "        'tau': -5,\n",
    "    },\n",
    "    'SparseTheta': {\n",
    "        'name': 'SparseTheta',\n",
    "        'tau': -4,\n",
    "    },\n",
    "    'DecorrelatorPhi': {\n",
    "        'name': 'DecorrelatorPhi',\n",
    "        'tau': 30_000_000,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание базовой пустой модели\n",
    "model_artm = new_default_model(params['topic_count'], dictionary)\n",
    "\n",
    "# Модель 0_0\n",
    "# Запуск регуляризатора SparsePhi\n",
    "\n",
    "# Обучение модели\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=150)\n",
    "\n",
    "# Вывод метрик модели\n",
    "model_print_results(model_artm)\n",
    "\n",
    "# Сохранение модели\n",
    "model_artm.save(\"news_model_0_0\")\n",
    "model_artm_0_0 = model_artm.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель 0_1\n",
    "# Запуск регуляризатора SparsePhi\n",
    "\n",
    "# Загрузка модели\n",
    "model_artm = model_artm_0_0.clone()\n",
    "\n",
    "# Регуляризатор SparsePhi\n",
    "# Создание регуляризатора, если он уже не создан\n",
    "if params['SparsePhi']['name'] not in list(model_artm.regularizers.data):\n",
    "    model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name=params['SparsePhi']['name']))\n",
    "# Настройка регуляризатора\n",
    "model_artm.regularizers[params['SparsePhi']['name']].tau = params['SparsePhi']['tau']\n",
    "\n",
    "# Обучение модели\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=params['num_collection_passes'])\n",
    "\n",
    "# Вывод метрик модели\n",
    "model_print_results(model_artm)\n",
    "\n",
    "# Сохранение модели\n",
    "model_artm.save(\"news_model_0_1\")\n",
    "model_artm_0_1 = model_artm.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель 0_2\n",
    "# Запуск регуляризатора SparseTheta к уже включенному SparsePhi\n",
    "\n",
    "# Загрузка модели\n",
    "model_artm = model_artm_0_1.clone()\n",
    "\n",
    "# Регуляризатор SparsePhi\n",
    "# Создание регуляризатора если он уже не создан\n",
    "if params['SparsePhi']['name'] not in list(model_artm.regularizers.data):\n",
    "    model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name=params['SparsePhi']['name']))\n",
    "# Настройка регуляризатора\n",
    "model_artm.regularizers[params['SparsePhi']['name']].tau = params['SparsePhi']['tau']\n",
    "\n",
    "# Регуляризатор SparseTheta\n",
    "# Создание регуляризатора если он уже не создан\n",
    "if params['SparseTheta']['name'] not in list(model_artm.regularizers.data):\n",
    "    model_artm.regularizers.add(artm.SmoothSparseThetaRegularizer(name=params['SparseTheta']['name']))\n",
    "# Настройка регуляризатора\n",
    "model_artm.regularizers[params['SparseTheta']['name']].tau = params['SparseTheta']['tau']\n",
    "\n",
    "# Обучение модели\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=params['num_collection_passes'])\n",
    "\n",
    "# Вывод метрик модели\n",
    "model_print_results(model_artm)\n",
    "\n",
    "# Сохранение модели\n",
    "model_artm.save(\"news_model_0_2\")\n",
    "model_artm_0_2 = model_artm.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель 0_3\n",
    "# Запуск регуляризатора DecorrelatorPhi к уже включенным SparsePhi, SparseTheta\n",
    "\n",
    "# Загрузка модели\n",
    "model_artm = model_artm_0_2.clone()\n",
    "\n",
    "# Регуляризатор SparsePhi\n",
    "# Создание регуляризатора если он уже не создан\n",
    "if params['SparsePhi']['name'] not in list(model_artm.regularizers.data):\n",
    "    model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name=params['SparsePhi']['name']))\n",
    "# Настройка регуляризатора\n",
    "model_artm.regularizers[params['SparsePhi']['name']].tau = params['SparsePhi']['tau']\n",
    "\n",
    "# Регуляризатор SparseTheta\n",
    "# Создание регуляризатора если он уже не создан\n",
    "if params['SparseTheta']['name'] not in list(model_artm.regularizers.data):\n",
    "    model_artm.regularizers.add(artm.SmoothSparseThetaRegularizer(name=params['SparseTheta']['name']))\n",
    "# Настройка регуляризатора\n",
    "model_artm.regularizers[params['SparseTheta']['name']].tau = params['SparseTheta']['tau']\n",
    "\n",
    "# Регуляризатор DecorrelatorPhi\n",
    "# Создание регуляризатора если он уже не создан\n",
    "if params['DecorrelatorPhi']['name'] not in list(model_artm.regularizers.data):\n",
    "    model_artm.regularizers.add(artm.DecorrelatorPhiRegularizer(name=params['DecorrelatorPhi']['name']))\n",
    "# Настройка регуляризатора\n",
    "model_artm.regularizers[params['DecorrelatorPhi']['name']].tau = params['DecorrelatorPhi']['tau']\n",
    "\n",
    "# Обучение модели\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=params['num_collection_passes'])\n",
    "\n",
    "# Вывод метрик модели\n",
    "model_print_results(model_artm)\n",
    "\n",
    "# Сохранение модели\n",
    "model_artm.save(\"news_model_0_3\")\n",
    "model_artm_0_3 = model_artm.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = model_artm.phi_\n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = model_artm.get_theta()\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

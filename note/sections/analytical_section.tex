\chapter{Аналитический раздел}
\todo[inline]{25 – 30 страниц}

%
\section{Постановка задачи}

\noindent\textbf{Целью} данной работы является разработка метода тематического моделирования для новостей на русском языке.

~\

\noindentДля достижения этой цели необходимо выполнить следующие основные \textbf{задачи}:

\begin{itemize}
    \item \todo{}Анализ существующих решений и выбор базового алгоритма тематического моделирования для классификация/категоризация новостей на русском языке
    \item Разработка программного продукта для сбора новостей на русском языке и подготовки данных для последующего анализа
    \item Подбор методов улучшения алгоритма и значений их параметров
    \item Обучение модели
    \item \todo{}проведение эксперимента
\end{itemize}

%
\section{Анализ предметной области}
\todo[inline]{проводится анализ предметной области}
\todo[inline]{выделяется основной объект исследования}

%%
\subsection{Задачи тематического моделирования}

\noindentЗадачи, для решения которых используется тематическое моделирование разбивают на 2 класса: \textbf{Автоматический анализ текста} и \textbf{систематизация больших объемов информации}.

~\

\noindentВ задачах автоматического анализа текста обычно выделяют следующие направления:

\begin{itemize}
    \item \textbf{Классификация и категоризация документов} - необходимо присвоить каждому документу соответствующие классы. Если классы имеют иерархическую структуру - говорят о категоризации.
    \item \textbf{Автоматическое аннотирование документов} - составление краткого обзора на документ, используя наиболее важные фразы.
    \item \textbf{Автоматическая суммаризация коллекций} - решение предыдущей задачи для большой коллекции документов.
    \item \textbf{Тематическая сегментация документов} - разбиение длинного документа части с различными темами.
\end{itemize}

~\

\noindentВ задачах систематизации больших объемов информации обычно выделяют следующие направления:

\begin{itemize}
    \item \textbf{Семантический (разведочный) поиск информации} - поиск по коллекции документов на базе тематического моделирования позволяет использовать длинный документ в качестве поискового запроса, а так же находить документы близкие по смыслу даже если ключевые слова, используемые при поиске отсутствуют в результатах поиска.
    \item \textbf{Визуализация тематической структуры коллекции} - все задачи связанные с графическим представлением больших массивов документов.
    \item \textbf{Анализ динамики развития тем} - обычно используется при наличии данных о времени создания документов в коллекции.
    \item \textbf{Тематический мониторинг новых поступлений} - автоматический мониторинг настроенных ресурсов на наличие новых документов, схожих по тематике с настроенным целевым документом.
    \item \textbf{Рекомендация документов пользователям} - создание систем рекомендации на основании данных о просмотренных документов пользователем и его активности.
\end{itemize}

%%
\subsection{Описание задачи}

В данной работе рассматривается задача \todo{}классификации и категоризации документов. В качестве документов выступают новости на русском языке. Необходимо с помощью выбранного метода и способов его усовершенствования разбить коллекцию новостей на темы, интерпретируемые человеком и получить возможность оценивать новый документ (новость) на принадлежность этим темам.

Особенностью тематического моделирования является возможность не использовать в процессе построения модели размеченные данные. То есть темы, на которые разбивается коллекция так же создаются по ходу формирования модели. 

Для лучшего понимания алгоритма рассмотрим детальнее процесс написания новости журналистом. Для начала работы он выбирает тему своей новостной статьи. Это, в свою очередь, влияет на то, какие слова он будет использовать. Очевидно, что если журналист решил написать новость про футбол, то слово <<мяч>> в таком документе появится с большей вероятностью, чем слово <<антиматерия>>. При этом если статья затрагивает финансовую сторону вопроса, то вероятности возникновения слов <<мяч>> и слово <<бюджет>> могут сравняться. В таком случае мы можем сказать что такая новость имеет минимум две темы - <<спорт>> и <<финансы>>, которые в свою очередь и породили слова <<мяч>> и <<бюджет>>. 

Продолжая эту аналогию можно представить себе любую новость как смесь разных тем. А каждое слово, встречающееся в новости как результат срабатывания события упоминания этого слова журналистом из тем, на которые он опирался создавая документ.

<<процесс порождения текстового документа вероятностной тематической моделью.png>>\todo{Вставить картинку}

%%
\subsection{Формализованное описание проблемы}
\todo[inline]{Необходимая существующая математика}
\todo[inline]{описание входных и выходных данных}
\todo[inline]{Откуда брать данные и какие они бывают}
\todo[inline]{описание критериев сравнения нескольких реализаций метода или алгоритма}

\noindentВходные данные:

\begin{itemize}
    \item Коллекция новостей на русском языке на разные темы в сети интернет.
\end{itemize}

~\

\noindentВыходные данные:

\begin{itemize}
    \item Обученная тематическая модель с настроенными регуляризаторами.
    \item Список тем с образующими их словами
    \item \todo{}Названия тем
\end{itemize}

~\

\noindentДопущения

\begin{itemize}
    \item Порядок слов в документе не важен (bag of words).
    \item Слова в документах генерируются темой, а не самим документом.
    \item Порядок документов в коллекции не важен.
    \item Каждое отношение документ-слово $(d,w)$ связано с некоторой темой $t \in T$.
    \item Коллекция представляет собой последовательность троек документ-слово-тема $(d,w,t)$.
    \item В теме не большое число образующих слов.
    \item В документе используется не большое число тем.
\end{itemize}

~\

\noindentПолучение данных:

\begin{itemize}
    \item Парсинг новостных агрегаторов
    \item Парсинг крупных новостных сайтов
\end{itemize}

~\

\noindentПодготовка данных:

\begin{itemize}
    \item Удаление форматирования текста
    \item Исправление опечаток
    \item Слияние слишком коротких текстов
    \item Выделение терминов
    \item Приведение слов к нормальной форме (лемматизация)
    \item Удаление слишком частых слов
    \item Удаление слишком редких слов
\end{itemize}

~\

\noindentПостановка задачи:

\noindentПусть:

\begin{itemize}
    \item $D$ - коллекция документов размера $n_d$ с документами $d$.
    \item $W$ - словарь терминов размера $n_w$ со словами $w$.
    \item $T$ - список тем размера размера $n_t$ с темами $t$.
    \item $n_{dw}$ - количество использований слова $w$ в документе $d$.
    \item Каждый документ состоит из слов: $d \subset W$
\end{itemize}

~\

\noindentТребуется найти параметры вероятностной порождающей тематической модели.

%
\section{Существующие методы}
\todo[inline]{обзор существующих путей/методов/решений и алгоритмов решения}
\todo[inline]{Классификация и кластеризация документов, VSM (Vector Space Model)}
\todo[inline]{LSA - Латентно-семантическое индексирование, SVD - Singular Value Decomposition}
\todo[inline]{? Графические модели}
\todo[inline]{PLSA - Probabilistic latent semantic analysis }
\todo[inline]{LDA - Latent Dirichlet allocation - латентное размещение Дирихле - специальный регуляризатор для Баеса}
\todo[inline]{? рLDA}
\todo[inline]{JPM - Join Probabilistic Model, AHMM - Aspect Hidden Markov Model, ATM - Autor-Topic Model, CTM - Correlated Topic Model}
\todo[inline]{ARTM - Additive Regularization for Topic Modeling}
\todo[inline]{\href{http://www.ispras.ru/proceedings/docs/2012/23/isp_23_2012_215.pdf}{Обзор}}
\todo[inline]{\href{http://dwl.kiev.ua/art/index.html}{dwl.kiev.ua - Дмитрия Владимировича Ландэ}}
\todo[inline]{обосновывается необходимость разработки нового или адаптации существующего метода или алгоритма}
\todo[inline]{выводы из обзора (лучше сравнительную таблицу) отсюда актуальность (никто не делал так/улучшаем то-то и то-то)}

%
\section{// Функциональные требования к }
\todo[inline]{Что мы хотим получить (это и будет "мостиком" к конструкторской)}
